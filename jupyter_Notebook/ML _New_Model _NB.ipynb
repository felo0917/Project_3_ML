{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled5.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOoSYJFdSEbvk8LBOhUKUhM"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"7JfW95LtPz0G"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YaSy8xz0QE7_","executionInfo":{"status":"ok","timestamp":1602722503560,"user_tz":420,"elapsed":3149,"user":{"displayName":"dany k","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDCbeDRUz17ZQwgdm4Xtqk_E2iIeJs6myMhdLylg=s64","userId":"15365450731390814726"}}},"source":["# Keras\n","import keras \n","from keras.models import *\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.preprocessing.image import ImageDataGenerator"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"9jHgl4-nP_47","executionInfo":{"status":"ok","timestamp":1602722509808,"user_tz":420,"elapsed":1657,"user":{"displayName":"dany k","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDCbeDRUz17ZQwgdm4Xtqk_E2iIeJs6myMhdLylg=s64","userId":"15365450731390814726"}},"outputId":"6a65048a-688c-438d-8e19-a2547832b234","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive \n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8SwAFV36vi-S","executionInfo":{"status":"ok","timestamp":1602722514976,"user_tz":420,"elapsed":3278,"user":{"displayName":"dany k","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDCbeDRUz17ZQwgdm4Xtqk_E2iIeJs6myMhdLylg=s64","userId":"15365450731390814726"}}},"source":["\n","train_data='/content/drive/My Drive/archive/train'\n","test_data='/content/drive/My Drive/archive/test'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"toGre2Gi0yxI"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mho5EQZUP_1F","executionInfo":{"status":"ok","timestamp":1602723557995,"user_tz":420,"elapsed":2048,"user":{"displayName":"dany k","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDCbeDRUz17ZQwgdm4Xtqk_E2iIeJs6myMhdLylg=s64","userId":"15365450731390814726"}},"outputId":"a3b24a71-1b75-44e6-b907-d73434822455","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["\n","train_datagen = ImageDataGenerator(rescale = 1./255, # To rescaling the image in range of [0,1]\n","                                   shear_range = 0.2, # To randomly shear the images \n","                                   zoom_range = 0.2, # To randomly zoom the images\n","                                   horizontal_flip = True) #  for randomly flipping half of the images horizontally \n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","train_generator = train_datagen.flow_from_directory(train_data,\n","                                                target_size=(250,250),\n","                                                batch_size=20, #Total no. of batches\n","                                                class_mode='categorical')\n","\n","test_generator = test_datagen.flow_from_directory(test_data,\n","                                            target_size=(250,250),\n","                                            batch_size=20,\n","                                            class_mode='categorical')\n"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Found 15557 images belonging to 23 classes.\n","Found 4002 images belonging to 23 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mosQzIyNxG34"},"source":["### Building CNN Model "]},{"cell_type":"markdown","metadata":{"id":"WtC1oXvxn8C4"},"source":["##### **My CNN model** : <br/>\n","{Input - Convolution + Relu  pooling - convolution + Relu pooling } **Feature learning** <br/>\n","{Flatten - Fully connected - Softmax} **Classification** \n"]},{"cell_type":"code","metadata":{"id":"eWjufhfZxH5H","executionInfo":{"status":"ok","timestamp":1602723700813,"user_tz":420,"elapsed":1212,"user":{"displayName":"dany k","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDCbeDRUz17ZQwgdm4Xtqk_E2iIeJs6myMhdLylg=s64","userId":"15365450731390814726"}},"outputId":"a8dfb731-5cdf-4c1a-cf3a-4b599d16c1e4","colab":{"base_uri":"https://localhost:8080/","height":867}},"source":["# Initializing CNN\n","model= Sequential()\n","\n","#  Adding 1st Convolution layer and Pooling layer\n","model.add(Convolution2D(32,(3,3),input_shape = (250,250,3), activation = 'relu'))\n","# layer poolling  to reduce the size the image interpretation \n","model.add(MaxPooling2D(pool_size = (2, 2)))\n","\n","#  Adding 2nd convolution layer and polling layer\n","model.add(Convolution2D(32,(3,3), activation = 'relu'))\n","\n","model.add(MaxPooling2D(pool_size = (2, 2)))\n","\n","\n","#Flattening the layers to convert the two dimentional vectort to a one dimentional vector \n","model.add(Flatten())\n","\n","# Full_Connection using 40 dense layers with different number of Neurones to increase accuracy \n","\n","model.add(Dense(units=32,activation = 'relu')) # using relu activation function (non linear function)\n","\n","model.add(Dense(units=64,activation = 'relu'))\n","\n","model.add(Dense(units=128,activation = 'relu'))\n","\n","model.add(Dense(units=256,activation = 'relu'))\n","\n","model.add(Dense(units=256,activation = 'relu'))\n","\n","model.add(Dense(units=256,activation = 'relu'))\n","\n","model.add(Dense(units=256,activation = 'relu'))\n","\n","model.add(Dense(units=582,activation = 'relu'))\n","\n","model.add(Dense(units=582,activation = 'relu'))\n","\n","model.add(Dense(units=1164,activation = 'relu'))\n","\n","model.add(Dense(units=1164,activation = 'relu'))\n","\n","model.add(Dense(units=1164,activation = 'relu'))\n","\n","model.add(Dense(units=1164,activation = 'relu'))\n","\n","model.add(Dense(units=1164,activation = 'relu'))\n","\n","model.add(Dense(units=1164,activation = 'relu'))\n","\n","# model.add(Dense(units=1164,activation = 'relu'))\n","\n","# model.add(Dense(units=1164,activation = 'relu'))\n","\n","# model.add(Dense(units=2328,activation = 'relu'))\n","\n","# model.add(Dense(units=2328,activation = 'relu'))\n","\n","# model.add(Dense(units=2328,activation = 'relu'))\n","\n","# model.add(Dense(units=2328,activation = 'relu'))\n","\n","# model.add(Dense(units=2328,activation = 'relu'))\n","\n","# model.add(Dense(units=2328,activation = 'relu'))\n","\n","# model.add(Dense(units=2328,activation = 'relu'))\n","\n","# model.add(Dense(units=2328,activation = 'relu'))\n","\n","# model.add(Dense(units=2328,activation = 'relu'))\n","\n","# model.add(Dense(units=2328,activation = 'relu'))\n","\n","# model.add(Dense(units=2328,activation = 'relu'))\n","\n","# model.add(Dense(units=2328,activation = 'relu'))\n","\n","# model.add(Dense(units=2328,activation = 'relu'))\n","\n","# model.add(Dense(units=2328,activation = 'relu'))\n","\n","# model.add(Dense(units=2328,activation = 'relu'))\n","\n","# model.add(Dense(units=2328,activation = 'relu'))\n","\n","# model.add(Dense(units=3492,activation = 'relu'))\n","\n","# model.add(Dense(units=3492,activation = 'relu'))\n","\n","# model.add(Dense(units=3492,activation = 'relu'))\n","\n","# model.add(Dense(units=3492,activation = 'relu'))\n","\n","# model.add(Dense(units=3492,activation = 'relu'))\n","\n","# model.add(Dense(units=3492,activation = 'relu'))\n","\n","# model.add(Dense(units=3492,activation = 'relu'))\n","\n","# model.add(Dense(units=3492,activation = 'relu'))\n","\n","# model.add(Dense(units=3492,activation = 'relu'))\n","\n","# model.add(Dense(units=3492,activation = 'relu'))\n","\n","model.add(Dense(units=23,activation = 'softmax')) # No. classes > 2 --> softmax instead of sigmoid \n","\n","model.summary()"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_14 (Conv2D)           (None, 248, 248, 32)      896       \n","_________________________________________________________________\n","max_pooling2d_14 (MaxPooling (None, 124, 124, 32)      0         \n","_________________________________________________________________\n","conv2d_15 (Conv2D)           (None, 122, 122, 32)      9248      \n","_________________________________________________________________\n","max_pooling2d_15 (MaxPooling (None, 61, 61, 32)        0         \n","_________________________________________________________________\n","flatten_7 (Flatten)          (None, 119072)            0         \n","_________________________________________________________________\n","dense_107 (Dense)            (None, 32)                3810336   \n","_________________________________________________________________\n","dense_108 (Dense)            (None, 64)                2112      \n","_________________________________________________________________\n","dense_109 (Dense)            (None, 128)               8320      \n","_________________________________________________________________\n","dense_110 (Dense)            (None, 256)               33024     \n","_________________________________________________________________\n","dense_111 (Dense)            (None, 256)               65792     \n","_________________________________________________________________\n","dense_112 (Dense)            (None, 256)               65792     \n","_________________________________________________________________\n","dense_113 (Dense)            (None, 256)               65792     \n","_________________________________________________________________\n","dense_114 (Dense)            (None, 582)               149574    \n","_________________________________________________________________\n","dense_115 (Dense)            (None, 582)               339306    \n","_________________________________________________________________\n","dense_116 (Dense)            (None, 1164)              678612    \n","_________________________________________________________________\n","dense_117 (Dense)            (None, 1164)              1356060   \n","_________________________________________________________________\n","dense_118 (Dense)            (None, 1164)              1356060   \n","_________________________________________________________________\n","dense_119 (Dense)            (None, 1164)              1356060   \n","_________________________________________________________________\n","dense_120 (Dense)            (None, 1164)              1356060   \n","_________________________________________________________________\n","dense_121 (Dense)            (None, 1164)              1356060   \n","_________________________________________________________________\n","dense_122 (Dense)            (None, 23)                26795     \n","=================================================================\n","Total params: 12,035,899\n","Trainable params: 12,035,899\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tQuhNBIe6it2"},"source":[""]},{"cell_type":"code","metadata":{"id":"FxhzvkLFP_ya","executionInfo":{"status":"ok","timestamp":1602723712589,"user_tz":420,"elapsed":874,"user":{"displayName":"dany k","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgDCbeDRUz17ZQwgdm4Xtqk_E2iIeJs6myMhdLylg=s64","userId":"15365450731390814726"}}},"source":["# Compiling CNN\n","model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"N9tD6vOUP_vt"},"source":["# Fitting CNN to images\n","# model.fit_generator(train_generator,\n","#                          samples_per_epoch=155, # Total training images\n","#                          nb_epoch = 15, # Total no. of epochs\n","#                          validation_data = test_generator,\n","#                          validation_steps = 40) # Total testing images\n","# from keras.callbacks import History \n","# history= History()\n","# model.fit_generator(\n","#         train_generator,\n","#         steps_per_epoch=15557,\n","#         epochs=15, callbacks=[history],\n","#         validation_data=test_generator,\n","#        validation_steps=4002)\n","nb_epoch = 15\n","nb_train_samples = 15557\n","nb_validation_samples = 4002\n","model.fit_generator(\n","        train_generator,\n","        steps_per_epoch=nb_train_samples,\n","        epochs=nb_epoch,\n","        validation_data=test_generator,\n","       validation_steps=nb_validation_samples)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OKnR2MVO4f05"},"source":[""]},{"cell_type":"code","metadata":{"id":"zibYuYXABaLr"},"source":["#step8 saving model \n","\n","# classifier.save(\"model.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y_cGbpYyP_s0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z9ObyrxqP_pF"},"source":[""],"execution_count":null,"outputs":[]}]}